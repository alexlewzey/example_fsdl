{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "lr = 0.02\n",
    "batch_size = 65536\n",
    "# batch_size = None\n",
    "quick_run = {\n",
    "'max_epochs': None,\n",
    "# 'limit_train_batches': 0.1,\n",
    "# 'limit_val_batches': 0.1,\n",
    "# 'limit_test_batches': 0.1,\n",
    "}\n",
    "fast_dev_run_kwargs = {'fast_dev_run': True, 'enable_checkpointing': False}\n",
    "overfit_batches_kwargs = {'overfit_batches': True, 'enable_checkpointing': False}\n",
    "large_model = {'precision': \"16-mixed\"}\n",
    "grad_accum = {'accumulate_grad_batches': 7}\n",
    "resume_training = {'ckpt_path': 'path/to/ckpt'}\n",
    "arcitecture_name = 'dnn' # linear_regression | dnn\n",
    "run_name = arcitecture_name\n",
    "experiemnt_name = \"mnist-classifier\"\n",
    "dir_artifacts = dir_artifacts/arcitecture_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_in, n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, n_in:int, h1: int, h2: int, n_out:int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_in, h1)\n",
    "        self.bn1 = nn.BatchNorm1d(h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.bn2 = nn.BatchNorm1d(h2)\n",
    "        self.fc3 = nn.Linear(h2, n_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MNISTClassifier(L.LightningModule):\n",
    "    def __init__(self, model, lr:float=2e-2):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_func = F.cross_entropy\n",
    "        self.lr = lr\n",
    "        self.example_input_array = torch.randn(5, 784)\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _step(self, batch, idx, set_name: str):\n",
    "        x,y=batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        pred = self(x)\n",
    "        loss = self.loss_func(pred, y)\n",
    "        self.log(f'{set_name}_loss', loss, prog_bar=True)\n",
    "        acc = self.accuracy(pred, y)\n",
    "        self.log(f'{set_name}_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, idx):\n",
    "        return self._step(batch, idx, 'train')\n",
    "\n",
    "    def validation_step(self, batch, idx):\n",
    "        return self._step(batch, idx, 'valid')\n",
    "\n",
    "    def test_step(self, batch, idx):\n",
    "        return self._step(batch, idx, 'test')\n",
    "\n",
    "    def predict_step(self, batch, idx,  dataloader_idx=0):\n",
    "        return self(batch[0])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(params=self.parameters(), lr=self.lr)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def plot_samples(preds, x, y, losses, idxs, rows=5, cols=6, path: Path | str = None):\n",
    "    preds, x, y, losses = map(lambda t:t.detach().numpy(), (preds, x, y, losses))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 16))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            idx = idxs[(i * cols) + j]\n",
    "            label = f'actual={y[idx]:.0f},pred={preds[idx]:.0f},loss={losses[idx]:.2f}'        \n",
    "            ax = axes[i, j]\n",
    "            ax.imshow(x[idx].reshape(28, 28), cmap='gray')\n",
    "            ax.set_title(label)\n",
    "            ax.axis('off')\n",
    "    plt.suptitle(\"Predictions with highest loss\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.94)\n",
    "    if path:\n",
    "        fig.savefig(Path(path).as_posix())\n",
    "        plt.close()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_top_losses(preds, x, y, losses, **kwargs):\n",
    "    _, idxs = losses.topk(100)\n",
    "    return plot_samples(preds=preds, x=x, y=y, losses=losses, idxs=idxs, **kwargs)\n",
    "    \n",
    "\n",
    "def plot_random_samples(preds, x, y, losses, **kwargs):\n",
    "    idxs = random.sample(range(len(x)), k=100)\n",
    "    return plot_samples(preds=preds, x=x, y=y, losses=losses, idxs=idxs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('file://' + dir_mlruns.as_posix())\n",
    "mlflow.set_experiment(experiment_name=experiemnt_name)\n",
    "mlflow.pytorch.autolog()\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    data = MNISTDataModule(dir_mnist.as_posix())\n",
    "    arcitectures = {\n",
    "        'linear_regression': LinearRegression(784, 10),\n",
    "        'dnn': DNN(784, 1024, 256, 10, dropout=0.5),\n",
    "    }\n",
    "    arcitecture = arcitectures[arcitecture_name]\n",
    "    model = MNISTClassifier(model=arcitecture)\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(every_n_epochs=2),\n",
    "        EarlyStopping(monitor=\"valid_loss\"),\n",
    "        StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "    ]\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=experiemnt_name,\n",
    "        run_id=mlflow.active_run().info.run_id,\n",
    "        log_model=True,\n",
    "        tracking_uri=uri_mlruns\n",
    "    )\n",
    "    trainer = L.Trainer(callbacks=callbacks, logger=mlf_logger, **quick_run)\n",
    "    tuner = Tuner(trainer)\n",
    "    if lr:\n",
    "        tuned_lr = lr\n",
    "    else:\n",
    "        lr_finder = tuner.lr_find(model, datamodule=data)\n",
    "        fig = lr_finder.plot(suggest=True)\n",
    "        fig.savefig((dir_artifacts/'lr_finder.png').as_posix())\n",
    "        plt.close()\n",
    "        tuned_lr = lr_finder.suggestion()\n",
    "        print(f'tuned_lr={tuned_lr:.3f}')\n",
    "\n",
    "    if batch_size:\n",
    "        tuned_batch_size = batch_size\n",
    "    else:\n",
    "        tuned_batch_size = tuner.scale_batch_size(model, datamodule=data, mode='power')\n",
    "        print(f'tuned_batch_size={tuned_batch_size:,}')\n",
    "\n",
    "    model = MNISTClassifier(model=arcitecture, lr=tuned_lr)\n",
    "    data = MNISTDataModule(dir_mnist.as_posix(), batch_size=tuned_batch_size)\n",
    "    trainer.fit(model, datamodule=data)\n",
    "    trainer.save_checkpoint((dir_artifacts / \"final_model.ckpt\").as_posix())\n",
    "\n",
    "    # calculating loss\n",
    "    trainer.predict(model, datamodule=data)\n",
    "    losses = Tensor([F.cross_entropy(model(x[None,]), y[None,]) for x, y in tqdm(data.ds_predict)])\n",
    "    ds = data.ds_predict\n",
    "    preds = model(ds.x).argmax(1)\n",
    "    # plotting\n",
    "    fig = plot_top_losses(preds, ds.x, ds.y, losses, path=dir_artifacts/'predictions_with_highest_loss.png')\n",
    "    fig = plot_random_samples(preds, ds.x, ds.y, losses, path=dir_artifacts/'predictions_sample.png')\n",
    "\n",
    "    trainer.test(model, data)\n",
    "    mlflow.log_artifacts(dir_artifacts.as_posix())\n",
    "\n",
    "mlflow.pytorch.autolog(disable=True)\n",
    "launch_mlflow_ui(uri=uri_mlruns, run=run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
